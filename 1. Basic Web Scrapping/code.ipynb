{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a4c36b3",
   "metadata": {},
   "source": [
    "# Homework 02 \n",
    "\n",
    "### Q1 : \n",
    "- Use your browser's development tools to find a unique way to access its list price and its current price. What do you choose? Please remember, you can choose multiple selectors to get where you want to be. E.g., you may choose to select \"span.class1 p.class2\" to select the \"p\" of class \"class2\" inside of the \"span\" of class \"class1\".\n",
    "- Store the prices to strings.\n",
    "- Use Python's (or Java's) regex (!!) functionality to convert the prices to \"1234.56\" (no dollar sign, comma, just a \".\" separator for cents). Print both, the list price and the current price to screen / terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "9e19c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33b07b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36\"}\n",
    "url= \"https://www.tigerdirect.com/applications/SearchTools/item-details.asp?EdpNo=1501390\"\n",
    "page = requests.get(url, headers = headers)\n",
    "# Create a beautifulsoup object \n",
    "soup = BeautifulSoup(page.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b28d2736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List price is $1,399.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$1,399.99'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List price \n",
    "list_prices = soup.select(\"span del\")\n",
    "for i in list_prices:\n",
    "    print('List price is',i.text)\n",
    "#store price to string  \n",
    "ListPrice = i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "bee276a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Price is $1,029.99         \n"
     ]
    }
   ],
   "source": [
    "#Current price \n",
    "current_prices = soup.select(\"div.pdp-price p.final-price span.sr-only\")\n",
    "for i in current_prices:\n",
    "    print(\"Current Price is\", i.text.replace('\\n', '').replace('\\r', '').replace(\"          \", \" \").replace('and','.').replace('cents','').replace(\" . \",'.'))\n",
    "    \n",
    "#store price to string  \n",
    "CurrentPrice = i.text.replace('\\n', '').replace('\\r', '').replace(\"          \", \" \").replace('and','.').replace('cents','').replace(\" . \",'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "fc10fafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399.99\n",
      "1029.99         \n"
     ]
    }
   ],
   "source": [
    "print(re.sub(\"[$,]\", \"\", ListPrice))\n",
    "print(re.sub(\"[$,]\", \"\", CurrentPrice))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d62f2",
   "metadata": {},
   "source": [
    "### Q2. \n",
    "- Loads \"https://www.usnews.com/\" \"finds\" its current \"Top Stories\" (do not hard-code it's URL!) (You may use your browser's dev tools to find a functioning way to access all the \"Top Stories\" and then implement the access to them in your code.)\n",
    "- Read + print the URL of the _second_ current top story to the screen (terminal). Load that page \n",
    "- Read + print the header as well as the first 3 sentences of the main body to the screen\n",
    "    - Example: the current _second_ \"Top Stories\" is \"Trump Org Gets Max Fine for Tax Fraud\" I want your code to load \"https://www.usnews.com/\", then read all the \"Top Stories\" (currently \"Biden Invited to Address Congress\", \"Trump Org Gets Max Fine for Tax Fraud\", ...), get the URL that the second top story links to (\"https://www.usnews.com/news/national-news/articles/2023-01-13/trump-organization-sentenced-to-pay-1-6-million-for-tax-fraud\"; this information is stored in the \"href\" property of the tag \"a\", i.e., '<a href=\"https://...\">...</a>', store the link to a string + print it to screen, then load the content of the string and read + print the header as well as the first 3 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "58b68e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_01= \"https://www.usnews.com\"\n",
    "page_01 = requests.get(url_01, headers = headers)\n",
    "# Create a beautifulsoup object \n",
    "soup_01 = BeautifulSoup(page_01.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c14a5",
   "metadata": {},
   "source": [
    "#### Get the headline of the second \"Top Stories\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "a45edc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Biden: ‘No Regrets’ on Disclosure Delay'"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method 01\n",
    "temp = soup_01.find_all('h3', \n",
    "                        class_ = 'Heading-sc-1w5xk2o-0 ContentBox__StoryHeading-sc-1egb8dt-3 MRvpF fqJuKa story-headline')[2]\n",
    "#method 02\n",
    "temp = soup_01.find_all('h3', \n",
    "                       attrs = {'class': 'Heading-sc-1w5xk2o-0 ContentBox__StoryHeading-sc-1egb8dt-3 MRvpF fqJuKa story-headline'})[2]\n",
    "\n",
    "headline = temp.text\n",
    "headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25dbad",
   "metadata": {},
   "source": [
    "#### Get the link of the second \"Top Stories\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "4f21ad01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.usnews.com/news/politics/articles/2023-01-19/biden-says-he-has-no-regrets-about-his-handling-of-documents'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = soup_01.find_all('h3',class_ = 'Heading-sc-1w5xk2o-0 ContentBox__StoryHeading-sc-1egb8dt-3 MRvpF fqJuKa story-headline')[2].a.get('href')\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51833688",
   "metadata": {},
   "source": [
    "#### Get the first 3 sentences of the second \"Top Stories\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "c22547fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_02= link\n",
    "page_02 = requests.get(url_02, headers = headers)\n",
    "# Create a beautifulsoup object \n",
    "soup_02 = BeautifulSoup(page_02.text, 'lxml')\n",
    "\n",
    "soup_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "d1182f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'President Biden told reporters Thursday that he has no regrets about how the administration handled the disclosure of the discovery of classified documents at his home and off-White House campus office, saying he was confident the investigations would show nothing untoward had occurred.'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\"As soon as we found the handful of documents were filed in the wrong place, we immediately turned them over to the Archives and the Justice Department,\" Biden said from a pier at Seacliff State Beach in Aptos, California, where he was delivering remarks after touring storm damage in the state.'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Chiding reporters briefly for asking about the documents instead of the emergency response to the California storm, Biden added, \"We\\'re fully cooperating and looking forward to this being resolved quickly. I think you\\'re going to find there\\'s nothing there.'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = soup_02.find_all('div', class_ = 'Raw-slyvem-0 bCYKCn')[0].p.text\n",
    "p2 = soup_02.find_all('div', class_ = 'Raw-slyvem-0 bCYKCn')[1].p.text\n",
    "p3 = soup_02.find_all('div', class_ = 'Raw-slyvem-0 bCYKCn')[2].p.text\n",
    "p1\n",
    "p2\n",
    "p3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
